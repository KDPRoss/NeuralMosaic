{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralMosaic\n",
    "### A CNN + Cosine-Similarity-Based Photomosaic Generator\n",
    "### Copyright 2018 K.D.P.Ross\n",
    "\n",
    "This code is licensed only for study and personal enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import progressbar\n",
    "from progressbar import ProgressBar\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have the slightest hope of running this, you will need:\n",
    "- `./weightz.npz`: pretrained weights for VGG-19\n",
    "- `./ImageTiles.txt`: a one-filename-per-line list of the tiles to use (along with the actual tiles (of size `tileSize`x`tileSize`) wherever it says that they'll be; probably want at least ~100k images) ⟦ N.b., things will go terribly wrong if the dimensions of the tile images is inconsistent! ⟧\n",
    "- `test.jpg`: an input image for which to generate a photomosaic; best if it's a mult. of the `tileSize`\n",
    "- a fair bit of RAM (with `conv4_2`, I saw peak at ~30GiB) and a half-decent GPU, especially if you use one of the earlier layers for `layerToUse` (Spoiler: 640k will *not* be enough.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters / Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Knobs' that may be worth twiddling.\n",
    "\n",
    "weightsFile    = 'weightz.npz'\n",
    "filesFile      = 'ImageTiles.txt'\n",
    "inImage        = 'test.png'\n",
    "outImage       = 'joined.png'\n",
    "tileSize       = 32\n",
    "batchSize      = 256 # Scale this down if your TF b0rks when it tries to run on your GPU.\n",
    "colourChannels = 3 # Things could get interesting if you change *this*!\n",
    "layerToUse     = 'conv4_2' # Recommended layers to try: 'conv3_2', 'conv4_2', 'conv5_4'. (If you're low on RAM / have a crap GPU, go for '5_4', for obvious reasons.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadList(f):\n",
    "    with open(f) as reader:\n",
    "        return [ x.strip() for x in reader ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant weight / bias matrices from the pretrained\n",
    "# VGG-19 model. These ought to be freely available, but\n",
    "# you'll need to dump them into a Numpy file.\n",
    "\n",
    "weightKeys = set([ 'conv1_1W', 'conv1_1b', 'conv1_2W', 'conv1_2b', 'conv2_1W', 'conv2_1b', 'conv2_2W', 'conv2_2b', 'conv3_1W', 'conv3_1b', 'conv3_2W', 'conv3_2b', 'conv3_3W', 'conv3_3b', 'conv3_4W', 'conv3_4b', 'conv4_1W', 'conv4_1b', 'conv4_2W', 'conv4_2b', 'conv4_3W', 'conv4_3b', 'conv4_4W', 'conv4_4b', 'conv5_1W', 'conv5_1b', 'conv5_2W', 'conv5_2b', 'conv5_3W', 'conv5_3b', 'conv5_4W', 'conv5_4b' ])\n",
    "weights    = np.load(weightsFile)\n",
    "\n",
    "assert weightKeys <= set(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Const's that we couldn't compute.\n",
    "\n",
    "strides     = [ 1, 1, 1, 1 ]\n",
    "sizePool    = [ 1, 2, 2, 1 ]\n",
    "stridesPool = [ 1, 2, 2, 1 ]\n",
    "padSame     = 'SAME'\n",
    "\n",
    "# We'll use two kinds of layers for the VGG model: 2d conv's\n",
    "# + Relu and avg. pooling (I guess max. pooling wasn't\n",
    "# popular at the time?); left off the final avg.-pool. layer\n",
    "# because we'll never use it.\n",
    "\n",
    "def convActivate(lPrev, lName):\n",
    "    return tf.nn.relu(tf.nn.conv2d(lPrev, \n",
    "                                   filter  = tf.constant(weights[ lName + 'W' ]),\n",
    "                                   strides = strides, \n",
    "                                   padding = padSame\n",
    "                                  ) + tf.constant(weights[ lName + 'b' ].flatten())\n",
    "                     )\n",
    "\n",
    "def avgPool(lPrev):\n",
    "    return tf.nn.avg_pool(lPrev,\n",
    "                          ksize   = sizePool,\n",
    "                          strides = stridesPool,\n",
    "                          padding = padSame\n",
    "                         )\n",
    "\n",
    "Input   = tf.placeholder(shape = (None, tileSize, tileSize, colourChannels),\n",
    "                                  dtype = 'float32'\n",
    "                                 )\n",
    "Conv1_1 = convActivate(Input, 'conv1_1')\n",
    "Conv1_2 = convActivate(Conv1_1, 'conv1_2')\n",
    "Pool1   = avgPool(Conv1_2)\n",
    "Conv2_1 = convActivate(Pool1, 'conv2_1')\n",
    "Conv2_2 = convActivate(Conv2_1, 'conv2_2')\n",
    "Pool2   = avgPool(Conv2_2)\n",
    "Conv3_1 = convActivate(Pool2, 'conv3_1')\n",
    "Conv3_2 = convActivate(Conv3_1, 'conv3_2')\n",
    "Conv3_3 = convActivate(Conv3_2, 'conv3_3')\n",
    "Conv3_4 = convActivate(Conv3_3, 'conv3_4')\n",
    "Pool3   = avgPool(Conv3_4)\n",
    "Conv4_1 = convActivate(Pool3, 'conv4_1')\n",
    "Conv4_2 = convActivate(Conv4_1, 'conv4_2')\n",
    "Conv4_3 = convActivate(Conv4_2, 'conv4_3')\n",
    "Conv4_4 = convActivate(Conv4_3, 'conv4_4')\n",
    "Pool4   = avgPool(Conv4_4)\n",
    "Conv5_1 = convActivate(Pool4, 'conv5_1')\n",
    "Conv5_2 = convActivate(Conv5_1, 'conv5_2')\n",
    "Conv5_3 = convActivate(Conv5_2, 'conv5_3')\n",
    "Conv5_4 = convActivate(Conv5_3, 'conv5_4')\n",
    "\n",
    "# This is somewhat clunky, but it'll let us index by name\n",
    "# instead of hard-coding indices.\n",
    "\n",
    "model = { 'input' : Input,\n",
    "          'conv1_1' : Conv1_1, 'conv1_2' : Conv1_2,\n",
    "          'conv2_1' : Conv2_1, 'conv2_2' : Conv2_2,\n",
    "          'conv3_1' : Conv3_1, 'conv3_2' : Conv3_2, 'conv3_3' : Conv3_3, 'conv3_4' : Conv3_4,\n",
    "          'conv4_1' : Conv4_1, 'conv4_2' : Conv4_2, 'conv4_3' : Conv4_3, 'conv4_4' : Conv4_4,\n",
    "          'conv5_1' : Conv5_1, 'conv5_2' : Conv5_2, 'conv5_3' : Conv5_3, 'conv5_4' : Conv5_4\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boot up TF.\n",
    "\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load / Preprocess Target / Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image, copying a greyscale image across to three\n",
    "# channels.\n",
    "\n",
    "def readImage(f):\n",
    "    raw = imageio.imread(f)\n",
    "\n",
    "    if 2 == len(raw.shape): # Greyscale image; just copy 3x; not quite right, but it'll do!\n",
    "        res = np.zeros((raw.shape[ 0 ], raw.shape[ 1 ], 3), dtype = raw.dtype)\n",
    "\n",
    "        for i in range(3):\n",
    "            res[ :, :, i ] = raw\n",
    "\n",
    "        return res\n",
    "    else:\n",
    "        return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library of output tiles.\n",
    "\n",
    "files = loadList(filesFile)\n",
    "\n",
    "with ProgressBar(max_value = len(files)) as prog:\n",
    "    imageMatrix = np.array([ readImage(x) for x in  prog(files) ])\n",
    "        \n",
    "assert (len(files), tileSize, tileSize, colourChannels) == imageMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature vec's for the output tiles.\n",
    "\n",
    "res = []\n",
    "\n",
    "with ProgressBar() as prog:\n",
    "    for i in prog(range(0, len(files), batchSize)):\n",
    "        batch = imageMatrix[ i : i + batchSize ]\n",
    "        bar   = s.run(model[ layerToUse ], feed_dict = { Input : batch })\n",
    "\n",
    "        res.append(bar)\n",
    "        \n",
    "res = np.concatenate(res, axis = 0) # Smoosh the batches together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectively, we'll crop the image to match the tile size;\n",
    "# method of cropping is utterly arbitrary; for best results,\n",
    "# use an image that's a multiple of the tile size! Then,\n",
    "# we'll chop up the image into (tileSize^2\n",
    "# x colourChannels)-sized tiles.\n",
    "\n",
    "inputRaw   = np.array(readImage(inImage))\n",
    "(r, c, _)  = inputRaw.shape\n",
    "inputTiles = []\n",
    "rowWidth   = int(c / tileSize)\n",
    "\n",
    "for i in range(int(r / tileSize)):\n",
    "    for j in range(rowWidth):\n",
    "        ir = i * tileSize\n",
    "        jc = j * tileSize\n",
    "\n",
    "        inputTiles.append(inputRaw[ ir : ir + tileSize, jc : jc + tileSize : ])\n",
    "\n",
    "inputMatrix = np.array(inputTiles)\n",
    "\n",
    "assert (len(inputTiles), tileSize, tileSize, colourChannels) == inputMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature vec's for the input tiles.\n",
    "\n",
    "resInput = []\n",
    "\n",
    "with ProgressBar() as prog:\n",
    "    for i in prog(range(0, len(inputTiles), batchSize)):\n",
    "        batch = inputMatrix[ i : i + batchSize ]\n",
    "        bar   = s.run(model[ layerToUse ], feed_dict = { Input : batch })\n",
    "\n",
    "        resInput.append(bar)\n",
    "        \n",
    "resInput = np.concatenate(resInput, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten things out to\n",
    "# <number-of-images>x<full-size-of-volume-per-image>;\n",
    "# literally don't care about ordering, so long as it's\n",
    "# consistent between output / input tiles.\n",
    "\n",
    "lhsFlat = res.reshape((res.shape[ 0 ], np.product(res.shape[ 1 : ])))\n",
    "rhsFlat = resInput.reshape((resInput.shape[ 0 ], np.product(resInput.shape[ 1 : ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cos. sim. to find 'semantically-closest' (at least\n",
    "# in the vec-space projection that we have) output tile for\n",
    "# each input tile; especially for gradients and\n",
    "# nearly-solid-colour areas, this will, unsurprisingly,\n",
    "# choose the same tile repeatedly; could be fun to, perhaps,\n",
    "# take the top `n` candidates and choose randomly among\n",
    "# them.\n",
    "\n",
    "sims        = cosine_similarity(lhsFlat, rhsFlat)\n",
    "tileIndices = np.argmax(sims, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh, probably should have used `itertools`.\n",
    "\n",
    "selectedTiles = [ files[ i ] for i in tileIndices ]\n",
    "tiles         = []\n",
    "\n",
    "while selectedTiles:\n",
    "    chunk         = selectedTiles[ : rowWidth ]\n",
    "    selectedTiles = selectedTiles[ rowWidth : ]\n",
    "    _             = tiles.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the output image by jamming the tiles in the\n",
    "# right places.\n",
    "\n",
    "outX      = tileSize * len(tiles[ 0 ])\n",
    "outY      = tileSize * len(tiles)\n",
    "outMatrix = np.zeros((outY, outX, 3), dtype = 'uint8')\n",
    "yOff      = 0\n",
    "\n",
    "for row in tiles:\n",
    "    xOff = 0\n",
    "\n",
    "    for img in row:\n",
    "        x                                                               = readImage(img)\n",
    "        outMatrix[ yOff : yOff + tileSize, xOff : xOff + tileSize, : ]  = x\n",
    "        xOff                                                           += tileSize\n",
    "\n",
    "    yOff += tileSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview of the output.\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.imshow(outMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our 'masterpiece' for future generations to marvel\n",
    "# at. Or something like that.\n",
    "\n",
    "imageio.imwrite(outImage, outMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up by closing the TF session.\n",
    "\n",
    "s.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
